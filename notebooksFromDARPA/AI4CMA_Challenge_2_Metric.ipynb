{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48762a07",
   "metadata": {},
   "source": [
    "### Scoring Your Dataset:\n",
    "#### 1. Run 'feature_f_score' function to calculate an f-score score for each predicted raster \n",
    "#### WARNING: Please, do not change the values set for the params 'difficult_weight', 'min_valid_range' and 'set_false_as', unless otherwise instructed, as these are the values on which the scores will be calculated during eval.\n",
    "#### 2. Bin the scores by feature type; pt, line and polygon\n",
    "#### 3. Find separate medians for each of the bins; median_pt, median_line and median_polygon\n",
    "#### 4. Final_Score=((2*median_polygon)+median_pt+median_line)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e8f6b",
   "metadata": {},
   "source": [
    "Description of the F-score:\n",
    "- In case of polygon features, the overlap between predicted and true pixels is calculated. In case of line and point features, we first find the closest pixel pairs i.e. true and predicted pixel pairs, as candidates for the score calculation, with a cutoff distance (min_valid_range param; currently set to .25), beyond which two pixels will be not be considered a valid pair. Here, instead of a direct overlap, one based on \"closeness\" is calculated; closeness=1, if the pixels overlap, and 0 if they are at the opposite ends of the diagonal.\n",
    "- We also weight the pixels differently in case of polygon features. The pixels that are detected by the color matching baseline are considered easy, and the rest are considered as hard. Currently, we set the hard pixels weight as .7 (in the difficult_weight param)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python libraries (Recommended python version 3.8.9)\n",
    "%pip install numpy==1.23.1 joblib==1.1.0\n",
    "%pip install matplotlib==3.2.2 opencv-python==4.6.0.66 tqdm==4.64.0 pandas==1.4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e07f559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc7af979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_distance_calculate(mat_true, mat_pred, min_valid_range=.1, parallel_workers=1):\n",
    "    \"\"\"\n",
    "    mat_true, mat_pred: 2d matrices, with 0s and 1s only\n",
    "    min_valid_range: the maximum distance in % of the largest size of the image (diagonal)\n",
    "        between a predicted pixel vs. a true one that will be considered\n",
    "        as valid to include in the scoring.\n",
    "    calculate_distance: when True this will not only calculate overlapping pixels\n",
    "        but also the distances between nearesttrue and predicted pixels\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_dist_pairs=[]\n",
    "    points_done_pred=set()\n",
    "    points_done_true=set()\n",
    "\n",
    "    # first calculate the overlapping pixels\n",
    "    mat_overlap=mat_pred*mat_true\n",
    "    for x_true, y_true in tqdm(np.argwhere(mat_overlap==1)):\n",
    "        lowest_dist_pairs.append((((x_true, y_true), (x_true, y_true)), 0.0)) \n",
    "        points_done_true.add((x_true, y_true))\n",
    "        points_done_pred.add((y_true, x_true))\n",
    "    print('len(lowest_dist_pairs) by overlapping only:', len(lowest_dist_pairs))\n",
    "    \n",
    "    diagonal_length=math.sqrt(math.pow(mat_true.shape[0], 2)+ math.pow(mat_true.shape[1], 2))\n",
    "    min_valid_range=int((min_valid_range*diagonal_length)/100) # in pixels\n",
    "    print('calculated pixel min_valid_range:', min_valid_range)\n",
    "\n",
    "    def nearest_pixels(x_true, y_true):\n",
    "        result=[]\n",
    "        # find all the points in pred withing min_valid_range rectangle\n",
    "        mat_pred_inrange=mat_pred[\n",
    "         max(x_true-min_valid_range, 0): min(x_true+min_valid_range, mat_true.shape[1]),\n",
    "            max(y_true-min_valid_range, 0): min(y_true+min_valid_range, mat_true.shape[0])\n",
    "        ]\n",
    "        for x_pred_shift, y_pred_shift in np.argwhere(mat_pred_inrange==1):\n",
    "            y_pred=max(y_true-min_valid_range, 0)+y_pred_shift\n",
    "            x_pred=max(x_true-min_valid_range, 0)+x_pred_shift\n",
    "            if (x_pred, y_pred) in points_done_pred:\n",
    "                continue\n",
    "            # calculate eucledean distances \n",
    "            dist_square=math.pow(x_true-x_pred, 2)+math.pow(y_true-y_pred, 2)\n",
    "            result.append((((x_true, y_true), (x_pred, y_pred)), dist_square))\n",
    "        return result\n",
    "\n",
    "    candidates=[(x_true, y_true) for x_true, y_true in tqdm(np.argwhere(mat_true==1)) if (x_true, y_true) not in points_done_true]\n",
    "    distances=Parallel(n_jobs=parallel_workers)(delayed(nearest_pixels)(x_true, y_true) for x_true, y_true in tqdm(candidates))\n",
    "    distances = [item for sublist in distances for item in sublist]\n",
    "\n",
    "    # sort based on distances\n",
    "    distances=sorted(distances, key=lambda x: x[1])\n",
    "\n",
    "    # find the lowest distance pairs\n",
    "    for ((x_true, y_true), (x_pred, y_pred)), distance in tqdm(distances):\n",
    "        if ((x_true, y_true) in points_done_true) or ((x_pred, y_pred) in points_done_pred):\n",
    "            # do not consider a taken point again\n",
    "            continue\n",
    "        # normalize all distances by diving by the diagonal length  \n",
    "        lowest_dist_pairs.append((((x_true, y_true), (x_pred, y_pred)), math.sqrt(float(distance))/diagonal_length)) \n",
    "        points_done_true.add((x_true, y_true))\n",
    "        points_done_pred.add((x_pred, y_pred))\n",
    "    \n",
    "    return lowest_dist_pairs\n",
    "\n",
    "\n",
    "def detect_difficult_pixels(map_image, binary_raster, legend_coor, plot=True, set_false_as='hard', color_range=4, baseline_raster=None):\n",
    "    \"\"\"\n",
    "    map_image: the image array for the map image\n",
    "    binary_raster: 2D array of any channel (out of 3 present) from the true binary raster image \n",
    "    legend_coor: coordinate for the legend feature, from the legend json file\n",
    "    plot: plots different rasters\n",
    "    set_false_as: when set to 'hard' the pixels that are not within the true polygon area will be considered hard\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (15,22)\n",
    "        \n",
    "    # detect pixels based on color of legend\n",
    "    if legend_coor is not None:\n",
    "        print('running baseline...')\n",
    "        pred_by_color=match_by_color(map_image.copy(), legend_coor, color_range=color_range, plot=plot)\n",
    "        if plot:\n",
    "            print('prediction based on color of legend:')\n",
    "            plt.imshow(pred_by_color)\n",
    "            plt.show()    \n",
    "    pred_by_color=(1-pred_by_color).astype(int) # flip, so the unpredicted become hard pixels\n",
    "    pred_by_color=binary_raster*pred_by_color # keep only the part within the true polygon\n",
    "    if plot:\n",
    "        print('flipped color predictions (the non-predicted will be hard pixels), within in the polygon range:')\n",
    "        plt.imshow(pred_by_color)\n",
    "        plt.show()\n",
    "    \n",
    "    if set_false_as=='hard':\n",
    "        # the pixels that are not within the true polygon should are deemed hard pixels\n",
    "        final_hard_pixels=(1-binary_raster)|pred_by_color\n",
    "    else:\n",
    "        # the outside pixels will be deemed easy!\n",
    "        final_hard_pixels=pred_by_color\n",
    "    \n",
    "    if plot:\n",
    "        print('final hard pixels (merged):')\n",
    "        plt.imshow(final_hard_pixels)\n",
    "        plt.show()\n",
    "\n",
    "    return final_hard_pixels\n",
    "\n",
    "def match_by_color(img, legend_coor, color_range=4, plot=False):\n",
    "    \"\"\"\n",
    "    img: the image array for the map image\n",
    "    legend_coor: coordinate for the legend feature, from the legend json file\n",
    "    \"\"\"\n",
    "    # get the legend coors and the predominant color\n",
    "    (x_min, y_min), (x_max, y_max) = legend_coor            \n",
    "    legend_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    if plot:\n",
    "        print('legend feature:')\n",
    "        plt.imshow(legend_img)\n",
    "        plt.show()\n",
    "    # take the median of the colors to find the predominant color\n",
    "    r=int(np.median(legend_img[:,:,0]))\n",
    "    g=int(np.median(legend_img[:,:,1]))\n",
    "    b=int(np.median(legend_img[:,:,2]))\n",
    "    sought_color=[r, g, b]\n",
    "    # capture the variations of legend color due to scanning errors\n",
    "    lower = np.array(sought_color)-color_range\n",
    "    lower[lower<0] = 0\n",
    "    lower=tuple(lower.tolist())\n",
    "    upper = np.array(sought_color)+color_range\n",
    "    upper[upper>255] = 255\n",
    "    upper=tuple(upper.tolist())\n",
    "    print('matching the color:', sought_color, 'with color range:', color_range, ', lower:', lower, 'upper:', upper)\n",
    "    # create a mask to only preserve current legend color in the basemap\n",
    "    pred_by_color = cv2.inRange(img, lower, upper)/255\n",
    "\n",
    "    return pred_by_color\n",
    "\n",
    "def feature_f_score(map_image_path, predicted_raster_path, true_raster_path, legend_json_path=None, min_valid_range=.1,\n",
    "                      difficult_weight=.7, set_false_as='hard', plot=True, color_range=4, parallel_workers=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    map_image_path: path to the the actual map image\n",
    "    predicted_raster_path: path to the the predicted binary raster image \n",
    "    true_raster_path: path to the the true binary raster image \n",
    "    legend_json_path: (only used for polygons) path to the json containing the coordinates for the corresponding legend (polygon) feature\n",
    "    min_valid_range: (only used for points and lines) the maximum distance in % of the largest size of the image (diagonal)\n",
    "        between a predicted pixel vs. a true one that will be considered\n",
    "        as valid to include in the scoring.\n",
    "    difficult_weight: (only used for polygons) float within [0, 1], weight for the difficlut pixels in the scores (only for polygins)\n",
    "    set_false_as: (only used for polygons) when set to 'hard' the pixels that are not within the true polygon area will be considered hard\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    true_raster=cv2.imread(true_raster_path)\n",
    "    true_raster=true_raster[:,:,0]\n",
    "    \n",
    "    predicted_raster=cv2.imread(predicted_raster_path)\n",
    "    if len(predicted_raster.shape)==3\n",
    "        predicted_raster=predicted_raster[:,:,0]\n",
    "    elif len(predicted_raster.shape)==2:\n",
    "        predicted_raster=predicted_raster\n",
    "    else:\n",
    "        print('predicted_raster shape is not 3 or 2!!!')\n",
    "        raise ValueError\n",
    "    \n",
    "    for item in np.unique(predicted_raster):\n",
    "        if int(item) not in [0, 1, 255]:\n",
    "            print('value in predicted raster:', int(item), 'not in permissible values:', [0, 1, 255])\n",
    "            raise ValueError\n",
    "    \n",
    "    predicted_raster[predicted_raster==255] = 1\n",
    "    \n",
    "    \n",
    "    extention=os.path.basename(true_raster_path).split('.')[-1]\n",
    "    \n",
    "    legend_feature=os.path.basename(true_raster_path).replace(os.path.basename(map_image_path).replace('.'+extention, '')+'_', '').replace('.'+extention, '')\n",
    "    feature_type=legend_feature.split('_')[-1]\n",
    "    print('feature type:', feature_type)\n",
    "    \n",
    "    start=datetime.now()\n",
    "    if plot or feature_type =='poly':\n",
    "        img=cv2.imread(map_image_path)\n",
    "        # img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    print('time check 1:', datetime.now()-start)\n",
    "    \n",
    "    # plot: overlay the true and predicted values on the map image\n",
    "    if plot:\n",
    "        im_copy=img.copy()\n",
    "        for center in np.argwhere(predicted_raster==1):\n",
    "            cv2.circle(im_copy, (center[1], center[0]), 1, (0,255,0), -1) # green\n",
    "        print('Predicted raster overlayed on map image:')\n",
    "        plt.rcParams[\"figure.figsize\"] = (15,22)\n",
    "        plt.imshow(im_copy)\n",
    "        plt.show()\n",
    "        im_copy=img.copy()\n",
    "        for center in np.argwhere(true_raster==1):\n",
    "            cv2.circle(im_copy, (center[1], center[0]), 1, (255,0,0), -1) # red\n",
    "        print('True raster overlayed on map image:')\n",
    "        plt.imshow(im_copy)\n",
    "        plt.show()\n",
    "    \n",
    "    start=datetime.now()\n",
    "    legend_coor=None\n",
    "    print('looking for legend_feature in the json:', legend_feature)\n",
    "    if legend_json_path is not None:\n",
    "        legends=json.loads(open(legend_json_path, 'r').read())\n",
    "        for shape in legends['shapes']:\n",
    "            if legend_feature ==shape['label']:\n",
    "                legend_coor=shape['points']\n",
    "        print('legend_coor:', legend_coor)\n",
    "    print('time check 2:', datetime.now()-start)\n",
    "    \n",
    "    mat_true, mat_pred=true_raster, predicted_raster\n",
    "                       \n",
    "    if feature_type in ['line', 'pt']: # for point and lines\n",
    "        lowest_dist_pairs=overlap_distance_calculate(mat_true, mat_pred,\n",
    "                                                     min_valid_range=min_valid_range, parallel_workers=parallel_workers)\n",
    "        print('len(lowest_dist_pairs):', len(lowest_dist_pairs))\n",
    "        sum_of_similarities=sum([1-item[1] for item in lowest_dist_pairs])\n",
    "        print('sum_of_similarities:', sum_of_similarities)\n",
    "        print('num all pixel pred:', len(np.argwhere(mat_pred==1)))\n",
    "        print('num all pixel true:', len(np.argwhere(mat_true==1)))\n",
    "        \n",
    "        num_mat_pred=np.sum(mat_pred) \n",
    "        num_mat_true=np.sum(mat_true)\n",
    "        precision=sum_of_similarities/num_mat_pred if num_mat_pred!=0 else 0.0\n",
    "        recall=sum_of_similarities/num_mat_true if num_mat_true!=0 else 0.0\n",
    "        \n",
    "    else: # for polygon\n",
    "        \n",
    "        start=datetime.now()\n",
    "        overlap=mat_true*mat_pred\n",
    "        print('time check 3:', datetime.now()-start)\n",
    "\n",
    "        if difficult_weight is not None:\n",
    "            \n",
    "            start=datetime.now()\n",
    "            difficult_pixels=detect_difficult_pixels(img, true_raster, legend_coor=legend_coor, set_false_as=set_false_as, plot=plot,\n",
    "                                                    color_range=color_range)\n",
    "            print('time check 4:', datetime.now()-start)\n",
    "            \n",
    "            start=datetime.now()\n",
    "            difficult_overlap=overlap*difficult_pixels\n",
    "            num_overlap_difficult=np.sum(difficult_overlap) \n",
    "            print('num_overlap_difficult:', num_overlap_difficult)\n",
    "            num_overlap_easy=np.sum(overlap-difficult_overlap) \n",
    "            print('num_overlap_easy:', num_overlap_easy)\n",
    "            points_from_overlap=(num_overlap_difficult*difficult_weight)+(num_overlap_easy*(1-difficult_weight))\n",
    "            print('points_from_overlap:', points_from_overlap)\n",
    "            \n",
    "            pred_difficult=mat_pred*difficult_pixels\n",
    "            num_mat_pred_difficult=np.sum(pred_difficult) \n",
    "            print('num_mat_pred_difficult:', num_mat_pred_difficult)\n",
    "            num_mat_pred_easy=np.sum(mat_pred-pred_difficult) \n",
    "            print('num_mat_pred_easy:', num_mat_pred_easy)\n",
    "            total_pred=(num_mat_pred_difficult*difficult_weight)+(num_mat_pred_easy*(1-difficult_weight))\n",
    "            print('total prediction points contended:', total_pred)\n",
    "            precision=points_from_overlap/total_pred if total_pred!=0 else 0.0\n",
    "            \n",
    "            \n",
    "            true_difficult=mat_true*difficult_pixels\n",
    "            num_mat_true_difficult=np.sum(true_difficult) \n",
    "            print('num_mat_true_difficult:', num_mat_true_difficult)\n",
    "            num_mat_true_easy= np.sum(mat_true-true_difficult) \n",
    "            print('num_mat_true_easy:', num_mat_true_easy)\n",
    "            total_true=(num_mat_true_difficult*difficult_weight)+(num_mat_true_easy*(1-difficult_weight))\n",
    "            print('total true points to be had:', total_true)\n",
    "            recall=points_from_overlap/total_true if total_true!=0 else 0.0\n",
    "            print('time check 5:', datetime.now()-start)\n",
    "        \n",
    "        else:\n",
    "            num_overlap=np.sum(overlap) \n",
    "            print('num_overlap:', num_overlap)\n",
    "            num_mat_pred=np.sum(mat_pred)\n",
    "            print('num_mat_pred:', num_mat_pred)\n",
    "            num_mat_true=np.sum(mat_true)\n",
    "            print('num_mat_true:', num_mat_true)\n",
    "\n",
    "            precision=num_overlap/num_mat_pred if num_mat_pred!=0 else 0.0\n",
    "            recall=num_overlap/num_mat_true if num_mat_true!=0 else 0.0\n",
    "        \n",
    "    \n",
    "    # calculate f-score\n",
    "    f_score=(2 * precision * recall) / (precision + recall) if precision+recall!=0 else 0.0\n",
    "\n",
    "    return precision, recall, f_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6327ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDefault settings for types of feature:\\n\\n# point\\nprecision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path,\\nlegend_json_path=None, min_valid_range=.1, difficult_weight=None, set_false_as=None, plot=False)\\n\\n# line\\nprecision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path, \\nlegend_json_path=None, min_valid_range=.1, difficult_weight=None, set_false_as=None, plot=False)\\n\\n# polygon\\nprecision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path,\\nlegend_json_path=legend_json_path, min_valid_range=None, difficult_weight=.7, set_false_as='hard', plot=False)\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Default settings for types of feature:\n",
    "\n",
    "# point\n",
    "precision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path,\n",
    "legend_json_path=None, min_valid_range=.1, difficult_weight=None, set_false_as=None, plot=False)\n",
    "\n",
    "# line\n",
    "precision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path, \n",
    "legend_json_path=None, min_valid_range=.1, difficult_weight=None, set_false_as=None, plot=False)\n",
    "\n",
    "# polygon\n",
    "precision, recall, f_score=feature_f_score(map_image_path, predicted_raster_path, true_raster_path,\n",
    "legend_json_path=legend_json_path, min_valid_range=None, difficult_weight=.7, color_range=4, set_false_as='hard', plot=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c1dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
