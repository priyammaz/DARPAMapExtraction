{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48762a07",
   "metadata": {},
   "source": [
    "### Scoring Your Dataset:\n",
    "#### 1. Run 'feature_f_score' function to calculate an f-score score for each predicted raster \n",
    "#### WARNING: Please, do not change the values set for the params 'difficult_weight', 'min_valid_range' and 'set_false_as', unless otherwise instructed, as these are the values on which the scores will be calculated during eval.\n",
    "#### 2. Bin the scores by feature type; pt, line and polygon\n",
    "#### 3. Find separate medians for each of the bins; median_pt, median_line and median_polygon\n",
    "#### 4. Final_Score=((2*median_polygon)+median_pt+median_line)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e8f6b",
   "metadata": {},
   "source": [
    "Description of the F-score:\n",
    "- In case of polygon features, the overlap between predicted and true pixels is calculated. In case of line and point features, we first find the closest pixel pairs i.e. true and predicted pixel pairs, as candidates for the score calculation, with a cutoff distance (min_valid_range param; currently set to .25), beyond which two pixels will be not be considered a valid pair. Here, instead of a direct overlap, one based on \"closeness\" is calculated; closeness=1, if the pixels overlap, and 0 if they are at the opposite ends of the diagonal.\n",
    "- We also weight the pixels differently in case of polygon features. The pixels that are detected by the color matching baseline are considered easy, and the rest are considered as hard. Currently, we set the hard pixels weight as .7 (in the difficult_weight param)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python libraries (Recommended python version 3.8.9)\n",
    "%pip install numpy==1.23.1 joblib==1.1.0\n",
    "%pip install matplotlib==3.2.2 opencv-python==4.6.0.66 tqdm==4.64.0 pandas==1.4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07f559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7af979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_distance_calculate(mat_true, mat_pred, min_valid_range=10, parallel_workers=1):\n",
    "    \"\"\"\n",
    "    mat_true, mat_pred: 2d matrices, with 0s and 1s only\n",
    "    min_valid_range: the maximum distance in % of the largest size of the image (diagonal)\n",
    "        between a predicted pixel vs. a true one that will be considered\n",
    "        as valid to include in the scoring.\n",
    "    calculate_distance: when True this will not only calculate overlapping pixels\n",
    "        but also the distances between nearesttrue and predicted pixels\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_dist_pairs=[]\n",
    "    points_done_pred=set()\n",
    "    points_done_true=set()\n",
    "\n",
    "    # first calculate the overlapping pixels\n",
    "    mat_overlap=mat_pred*mat_true\n",
    "    for x_true, y_true in tqdm(np.argwhere(mat_overlap==1)):\n",
    "        lowest_dist_pairs.append((((x_true, y_true), (x_true, y_true)), 0.0)) \n",
    "        points_done_true.add((x_true, y_true))\n",
    "        points_done_pred.add((y_true, x_true))\n",
    "    print('len(lowest_dist_pairs) by overlapping only:', len(lowest_dist_pairs))\n",
    "    \n",
    "    diagonal_length=math.sqrt(math.pow(mat_true.shape[0], 2)+ math.pow(mat_true.shape[1], 2))\n",
    "    min_valid_range=int((min_valid_range*diagonal_length)/100) # in pixels\n",
    "    print('calculated pixel min_valid_range:', min_valid_range)\n",
    "\n",
    "    def nearest_pixels(x_true, y_true):\n",
    "        result=[]\n",
    "        # find all the points in pred withing min_valid_range rectangle\n",
    "        mat_pred_inrange=mat_pred[\n",
    "         max(x_true-min_valid_range, 0): min(x_true+min_valid_range, mat_true.shape[1]),\n",
    "            max(y_true-min_valid_range, 0): min(y_true+min_valid_range, mat_true.shape[0])\n",
    "        ]\n",
    "        for x_pred_shift, y_pred_shift in np.argwhere(mat_pred_inrange==1):\n",
    "            y_pred=max(y_true-min_valid_range, 0)+y_pred_shift\n",
    "            x_pred=max(x_true-min_valid_range, 0)+x_pred_shift\n",
    "            if (x_pred, y_pred) in points_done_pred:\n",
    "                continue\n",
    "            # calculate eucledean distances \n",
    "            dist_square=math.pow(x_true-x_pred, 2)+math.pow(y_true-y_pred, 2)\n",
    "            result.append((((x_true, y_true), (x_pred, y_pred)), dist_square))\n",
    "        return result\n",
    "\n",
    "    candidates=[(x_true, y_true) for x_true, y_true in tqdm(np.argwhere(mat_true==1)) if (x_true, y_true) not in points_done_true]\n",
    "    distances=Parallel(n_jobs=parallel_workers)(delayed(nearest_pixels)(x_true, y_true) for x_true, y_true in tqdm(candidates))\n",
    "    distances = [item for sublist in distances for item in sublist]\n",
    "\n",
    "    # sort based on distances\n",
    "    distances=sorted(distances, key=lambda x: x[1])\n",
    "\n",
    "    # find the lowest distance pairs\n",
    "    for ((x_true, y_true), (x_pred, y_pred)), distance in tqdm(distances):\n",
    "        if ((x_true, y_true) in points_done_true) or ((x_pred, y_pred) in points_done_pred):\n",
    "            # do not consider a taken point again\n",
    "            continue\n",
    "        # normalize all distances by diving by the diagonal length  \n",
    "        lowest_dist_pairs.append((((x_true, y_true), (x_pred, y_pred)), math.sqrt(float(distance))/diagonal_length)) \n",
    "        points_done_true.add((x_true, y_true))\n",
    "        points_done_pred.add((x_pred, y_pred))\n",
    "    \n",
    "    return lowest_dist_pairs\n",
    "\n",
    "\n",
    "def detect_difficult_pixels(map_image, binary_raster, legend_coor, plot=True, set_false_as='hard'):\n",
    "    \"\"\"\n",
    "    map_image: the image array for the map image\n",
    "    binary_raster: 2D array of any channel (out of 3 present) from the true binary raster image \n",
    "    legend_coor: coordinate for the legend feature, from the legend json file\n",
    "    plot: plots different rasters\n",
    "    set_false_as: when set to 'hard' the pixels that are not within the true polygon area will be considered hard\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (15,22)\n",
    "        \n",
    "    # detect pixels based on color of legend\n",
    "    if legend_coor is not None:\n",
    "        pred_by_color=match_by_color(map_image.copy(), legend_coor, color_range=20)\n",
    "        if plot:\n",
    "            print('predicted based on color of legend:')\n",
    "            plt.imshow(pred_by_color)\n",
    "            plt.show()\n",
    "            \n",
    "    pred_by_color=(1-pred_by_color).astype(int) # flip, so the unpredicted become hard pixels\n",
    "    pred_by_color=binary_raster*pred_by_color # keep only the part within the true polygon\n",
    "    if plot:\n",
    "        print('hard pixel (flipped predictions) using the color predictions (in the polygon range):')\n",
    "        plt.imshow(pred_by_color)\n",
    "        plt.show()\n",
    "    \n",
    "    if set_false_as=='hard':\n",
    "        # the pixels that are not within the true polygon should are deemed hard pixels\n",
    "        final_hard_pixels=(1-binary_raster)|pred_by_color\n",
    "    else:\n",
    "        # the outside pixels will be deemed easy!\n",
    "        final_hard_pixels=pred_by_color\n",
    "    \n",
    "    if plot:\n",
    "        print('final hard pixels (merged):')\n",
    "        plt.imshow(final_hard_pixels)\n",
    "        plt.show()\n",
    "\n",
    "    return final_hard_pixels\n",
    "\n",
    "def match_by_color(img, legend_coor, color_range=20):\n",
    "    \"\"\"\n",
    "    img: the image array for the map image\n",
    "    legend_coor: coordinate for the legend feature, from the legend json file\n",
    "    \"\"\"\n",
    "    # get the legend coors and the predominant color\n",
    "    (x_min, y_min), (x_max, y_max) = legend_coor            \n",
    "    legend_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    # take the median of the colors to find the predominant color\n",
    "    r=int(np.median(legend_img[:,:,0]))\n",
    "    g=int(np.median(legend_img[:,:,1]))\n",
    "    b=int(np.median(legend_img[:,:,2]))\n",
    "    sought_color=[r, g, b]\n",
    "    print('matching the color:', sought_color, 'with color range:', color_range)\n",
    "    # capture the variations of legend color due to scanning errors\n",
    "    lower = np.array([x - color_range for x in sought_color], dtype=\"uint8\")\n",
    "    upper = np.array([x + color_range for x in sought_color], dtype=\"uint8\")\n",
    "    # create a mask to only preserve current legend color in the basemap\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    detected = cv2.bitwise_and(img, img, mask=mask)\n",
    "    # convert to grayscale \n",
    "    detected_gray = cv2.cvtColor(detected, cv2.COLOR_BGR2GRAY)\n",
    "    img_bw = cv2.threshold(detected_gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    # convert the grayscale image to binary image\n",
    "    pred_by_color = img_bw.astype(float) / 255\n",
    "    return pred_by_color\n",
    "\n",
    "def feature_f_score(map_image_path, predicted_raster_path, true_raster_path, legend_json_path=None, min_valid_range=.25,\n",
    "                      difficult_weight=.7, set_false_as='hard', plot=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    map_image_path: path to the the actual map image\n",
    "    predicted_raster_path: path to the the predicted binary raster image \n",
    "    true_raster_path: path to the the true binary raster image \n",
    "    legend_json_path: (only used for polygons) path to the json containing the coordinates for the corresponding legend (polygon) feature\n",
    "    min_valid_range: (only used for points and lines) the maximum distance in % of the largest length in the image i.e. the diagonal\n",
    "        between a predicted pixel vs. a true one that will be considered\n",
    "        as valid to include in the scoring.\n",
    "    difficult_weight: (only used for polygons) float within [0, 1], weight for the difficlut pixels in the scores (only for polygins)\n",
    "    set_false_as: (only used for polygons) when set to 'hard' the pixels that are not within the true polygon area will be considered hard\n",
    "    \"\"\"\n",
    "     \n",
    "    img=cv2.imread(map_image_path)\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    true_raster=cv2.imread(true_raster_path)\n",
    "    true_raster=true_raster[:,:,0]\n",
    "    \n",
    "    predicted_raster=cv2.imread(predicted_raster_path)\n",
    "    predicted_raster=predicted_raster[:,:,0]\n",
    "    \n",
    "    # plot: overlay the true and predicted values on the map image\n",
    "    if plot:\n",
    "        im_copy=img.copy()\n",
    "        for center in np.argwhere(predicted_raster==1):\n",
    "            cv2.circle(im_copy, (center[1], center[0]), 1, (0,255,0), -1) # green\n",
    "        print('Predicted raster overlayed on map image:')\n",
    "        plt.rcParams[\"figure.figsize\"] = (15,22)\n",
    "        plt.imshow(im_copy)\n",
    "        plt.show()\n",
    "        im_copy=img.copy()\n",
    "        for center in np.argwhere(true_raster==1):\n",
    "            cv2.circle(im_copy, (center[1], center[0]), 1, (255,0,0), -1) # red\n",
    "        print('True raster overlayed on map image:')\n",
    "        plt.imshow(im_copy)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    legend_feature=os.path.basename(true_raster_path).replace(os.path.basename(map_image_path).replace('.tif', '')+'_', '').replace('.tif', '')\n",
    "    feature_type=legend_feature.split('_')[-1]\n",
    "    print('feature type:', feature_type)\n",
    "    \n",
    "    legend_coor=None\n",
    "    if legend_json_path is not None:\n",
    "        legends=json.loads(open(legend_json_path, 'r').read())\n",
    "        for shape in legends['shapes']:\n",
    "            if legend_feature ==shape['label']:\n",
    "                legend_coor=legends['shapes'][0]['points']\n",
    "        print('legend_coor:', legend_coor)\n",
    "    \n",
    "    mat_true, mat_pred=true_raster, predicted_raster\n",
    "                       \n",
    "    if feature_type in ['line', 'pt']: # for point and lines\n",
    "        lowest_dist_pairs=overlap_distance_calculate(mat_true, mat_pred,\n",
    "                                                     min_valid_range=min_valid_range)\n",
    "        print('len(lowest_dist_pairs):', len(lowest_dist_pairs))\n",
    "        sum_of_similarities=sum([1-item[1] for item in lowest_dist_pairs])\n",
    "        print('sum_of_similarities:', sum_of_similarities)\n",
    "        print('num all pixel pred:', len(np.argwhere(mat_pred==1)))\n",
    "        print('num all pixel true:', len(np.argwhere(mat_true==1)))\n",
    "        precision=sum_of_similarities/len(np.argwhere(mat_pred==1))\n",
    "        recall=sum_of_similarities/len(np.argwhere(mat_true==1))\n",
    "    else: # for polygon\n",
    "        \n",
    "        overlap=mat_true*mat_pred\n",
    "        num_overlap=len(np.argwhere(overlap==1))\n",
    "        print('num_overlap:', num_overlap)\n",
    "        num_mat_pred=len(np.argwhere(mat_pred==1))\n",
    "        print('num_mat_pred:', num_mat_pred)\n",
    "        num_mat_true=len(np.argwhere(mat_true==1))\n",
    "        print('num_mat_true:', num_mat_true)\n",
    "        \n",
    "        if difficult_weight is not None:\n",
    "            \n",
    "            difficult_pixels=detect_difficult_pixels(img, true_raster, legend_coor=legend_coor, set_false_as=set_false_as, plot=plot)\n",
    "            \n",
    "            num_overlap_difficult=len(np.argwhere((overlap*difficult_pixels)==1))\n",
    "            print('num_overlap_difficult:', num_overlap_difficult)\n",
    "            num_overlap_easy=len(np.argwhere((overlap-(overlap*difficult_pixels))==1))\n",
    "            print('num_overlap_easy:', num_overlap_easy)\n",
    "            points_from_overlap=(num_overlap_difficult*difficult_weight)+(num_overlap_easy*(1-difficult_weight))\n",
    "            print('points_from_overlap:', points_from_overlap)\n",
    "            \n",
    "            num_mat_pred_difficult=len(np.argwhere((mat_pred*difficult_pixels)==1))\n",
    "            print('num_mat_pred_difficult:', num_mat_pred_difficult)\n",
    "            num_mat_pred_easy=len(np.argwhere((mat_pred-(mat_pred*difficult_pixels))==1))\n",
    "            print('num_mat_pred_easy:', num_mat_pred_easy)\n",
    "            total_pred=(num_mat_pred_difficult*difficult_weight)+(num_mat_pred_easy*(1-difficult_weight))\n",
    "            print('total prediction points contended:', total_pred)\n",
    "            precision=points_from_overlap/total_pred\n",
    "            \n",
    "\n",
    "            num_mat_true_difficult=len(np.argwhere((mat_true*difficult_pixels)==1))\n",
    "            print('num_mat_true_difficult:', num_mat_true_difficult)\n",
    "            num_mat_true_easy=len(np.argwhere((mat_true-(mat_true*difficult_pixels))==1))\n",
    "            print('num_mat_true_easy:', num_mat_true_easy)\n",
    "            total_true=(num_mat_true_difficult*difficult_weight)+(num_mat_true_easy*(1-difficult_weight))\n",
    "            print('total true points to be had:', total_true)\n",
    "            recall=points_from_overlap/total_true\n",
    "        \n",
    "        else:\n",
    "            precision=num_overlap/num_mat_pred\n",
    "            recall=num_overlap/num_mat_true\n",
    "        \n",
    "    \n",
    "    # calculate f-score\n",
    "    if precision+recall!=0:\n",
    "        f_score=(2 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f_score=0\n",
    "\n",
    "    return precision, recall, f_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6327ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
