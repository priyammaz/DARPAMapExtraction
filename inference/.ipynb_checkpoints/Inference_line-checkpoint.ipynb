{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b164f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from itertools import chain\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "from model_UNet import UNetCompiled\n",
    "from metrics import feature_f_score\n",
    "from map_mask import map_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203d028",
   "metadata": {},
   "source": [
    "### Given a map and legend name, prepare the patched data\n",
    "cut the whole map into (256*256) patches, cut the legend based on json file\n",
    "a subfolder \"filename_map_patches\" and \"filename_legend\" will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff610cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_patch(filename, legend, patch_dims = (256,256)):\n",
    "    \"\"\"\n",
    "    filename = 'VA_Lahore_bm.tif'   \n",
    "    legend = 'SOa_poly'\n",
    "    \"\"\"\n",
    "\n",
    "    filePath = os.path.join(working_dir, filename)\n",
    "    segmentation_file = filePath.split('.')[0]+'_'+legend+'.tif' \n",
    "    patch_dims = patch_dims\n",
    "    \n",
    "    map_patches_dir = os.path.join(working_dir, filename.split('.')[0]+'_map_patches')        \n",
    "        \n",
    "    map_im =  cv2.imread(filePath)\n",
    "\n",
    "    map_im_dims = map_im.shape\n",
    "    patch_overlap = 32\n",
    "    patch_step = patch_dims[1]-patch_overlap\n",
    "\n",
    "    # To patchify, the (width - patch_width) mod step_size = 0\n",
    "    shift_x = (map_im.shape[0]-patch_dims[0])%patch_step\n",
    "    shift_y = (map_im.shape[1]-patch_dims[1])%patch_step\n",
    "    shift_x_left = shift_x//2\n",
    "    shift_x_right = shift_x - shift_x_left\n",
    "    shift_y_left = shift_y//2\n",
    "    shift_y_right = shift_y - shift_y_left\n",
    "\n",
    "    shift_coord =  [shift_x_left, shift_x_right, shift_y_left, shift_y_right]\n",
    "\n",
    "    map_im_cut = map_im[shift_x_left:map_im.shape[0]-shift_x_right, shift_y_left:map_im.shape[1]-shift_y_right,:]\n",
    "    map_patchs = patchify(map_im_cut, (*patch_dims,3), patch_step)\n",
    "    \n",
    "    if not os.path.exists(map_patches_dir): \n",
    "        os.mkdir(map_patches_dir)\n",
    "        for i in range(map_patchs.shape[0]):\n",
    "            for j in range(map_patchs.shape[1]):\n",
    "                imageio.imwrite(os.path.join(map_patches_dir, '{0:02d}_{1:02d}.png'.format(i,j)), (map_patchs[i][j][0]).astype(np.uint8))\n",
    "\n",
    "    ## work on cropping the legend and save it to a subfolder \"filename_legend\"\n",
    "    legend_dir = os.path.join(working_dir, filename.split('.')[0]+'_legend')\n",
    "    \n",
    "#     if os.path.exists(os.path.join(legend_dir, legend+'.png')):\n",
    "#         return shift_coord, map_im_cut.shape, map_patchs.shape\n",
    "    \n",
    "    if not os.path.exists(legend_dir):\n",
    "        os.mkdir(legend_dir)\n",
    "\n",
    "    json_file = filePath.split('.')[0]+'.json'\n",
    "    with open(json_file, 'r') as f:\n",
    "        jsonData = json.load(f)\n",
    "    point_coord = []\n",
    "    for label_dict in jsonData['shapes']:\n",
    "        if label_dict['label'] == legend:\n",
    "            point_coord = label_dict['points']\n",
    "    if not point_coord: raise Exception(\"The provided legend does not exist: \", filename)\n",
    "    flatten_list = list(chain.from_iterable(point_coord))\n",
    "    \n",
    "    if point_coord[0][0] >= point_coord[1][0] or point_coord[0][1] >= point_coord[1][1]:\n",
    "        # print(\"Coordinate right is less than left:  \", filename, legend, point_coord)\n",
    "        x_low = min(int(point_coord[0][0]), int(point_coord[1][0]))\n",
    "        x_hi = max(int(point_coord[0][0]), int(point_coord[1][0]))\n",
    "        y_low = min(int(point_coord[0][1]), int(point_coord[1][1]))\n",
    "        y_hi = max(int(point_coord[0][1]), int(point_coord[1][1]))\n",
    "    elif (len(flatten_list)!=4):\n",
    "        x_coord = [x[0] for x in point_coord]\n",
    "        y_coord = [x[1] for x in point_coord]\n",
    "        x_low, y_low, x_hi, y_hi = int(min(x_coord)), int(min(y_coord)), int(max(x_coord)), int(max(y_coord))\n",
    "        # print(\"Point Coordinates number is not 4: \", filename, legend)\n",
    "    else: x_low, y_low, x_hi, y_hi = [int(x) for x in flatten_list]\n",
    "    legend_coor =  [(x_low, y_low), (x_hi, y_hi)]\n",
    "    shift_pixel  = 4\n",
    "    im_crop = map_im[y_low+shift_pixel:y_hi-shift_pixel, x_low+shift_pixel:x_hi-shift_pixel] # need to resize\n",
    "    #print(y_low+shift_pixel, y_hi-shift_pixel, x_low+shift_pixel, x_hi-shift_pixel)\n",
    "    im_crop_resize = cv2.resize(im_crop, dsize=patch_dims, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    imageio.imwrite(os.path.join(legend_dir, legend+'.png'), (im_crop_resize).astype(np.uint8))\n",
    "    \n",
    "    return legend_coor, shift_coord, map_im_cut.shape, map_patchs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93474d13",
   "metadata": {},
   "source": [
    "### create a testing data generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62369a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataGenerator(filename, legend, patch_dims = (256,256)):\n",
    "    \"\"\"\n",
    "    filename = 'VA_Lahore_bm.tif'\n",
    "    legend = 'fault_line'\n",
    "    \"\"\"\n",
    "    def load_img(patchName):\n",
    "        map_img = tf.io.read_file(patchName) # Read image file\n",
    "        map_img = tf.cast(tf.io.decode_png(map_img), dtype=tf.float32) / 255.0\n",
    "#         map_img = map_img[:,:,0:3]\n",
    "        \n",
    "        legendPath = os.path.join(working_dir, filename.split('.')[0]+'_legend', legend+'.png') \n",
    "\n",
    "        legend_img = tf.io.read_file(legendPath) # Read image file\n",
    "        legend_img = tf.cast(tf.io.decode_png(legend_img), dtype=tf.float32) / 255.0\n",
    "#         legend_img = legend_img[:,:,0:3]\n",
    "        \n",
    "        #augmented_img = data_augmentation(legend_img)\n",
    "        \n",
    "        img = tf.concat(axis=2, values = [map_img, legend_img])\n",
    "        img = img*2.0 - 1.0 # range(-1.0,1.0)\n",
    "        img = tf.image.resize(img, [256,256])\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    patch_dims = patch_dims\n",
    "    patchNames = sorted(glob(os.path.join(working_dir, filename.split('.')[0]+'_map_patches/*')))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(patchNames)\n",
    "    test_dataset = test_dataset.map(load_img)   \n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a7df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mask(filename, pad_unpatch_predicted_threshold):\n",
    "    filePath = os.path.join(working_dir, filename)\n",
    "    imarray = cv2.imread(filePath)\n",
    "    gray = cv2.cvtColor(imarray, cv2.COLOR_BGR2GRAY)  # greyscale image\n",
    "    # Detect Background Color\n",
    "    pix_hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "    background_pix_value = np.argmax(pix_hist, axis=None)\n",
    "\n",
    "    # Flood fill borders\n",
    "    height, width = gray.shape[:2]\n",
    "    corners = [[0,0],[0,height-1],[width-1, 0],[width-1, height-1]]\n",
    "    for c in corners:\n",
    "        cv2.floodFill(gray, None, (c[0],c[1]), 255)\n",
    "\n",
    "    # AdaptiveThreshold to remove noise\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 4)\n",
    "\n",
    "    # Edge Detection\n",
    "    thresh_blur = cv2.GaussianBlur(thresh, (11, 11), 0)\n",
    "    canny = cv2.Canny(thresh_blur, 0, 200)\n",
    "    canny_dilate = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "\n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny_dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Keeping only the largest detected contour.\n",
    "    contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "    wid, hight = pad_unpatch_predicted_threshold.shape[0], pad_unpatch_predicted_threshold.shape[1]\n",
    "    mask = np.zeros([wid, hight])\n",
    "    mask = cv2.fillPoly(mask, pts=[contour], color=(1,1,1)).astype(int)\n",
    "    masked_img = cv2.bitwise_and(pad_unpatch_predicted_threshold, mask)\n",
    "    \n",
    "    return masked_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c57af",
   "metadata": {},
   "source": [
    "### Loading a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c50a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 09:01:06.566258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13867 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0035:03:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "patch_dims = (256,256)\n",
    "unet = UNetCompiled(input_size=(*patch_dims,6), n_filters=16, n_classes=1)\n",
    "unet.load_weights(\"../model/saved_line_model/best_attention_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b6c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInferenceForEachLegend(filename, legend):\n",
    "    \"\"\"\n",
    "    filename = 'VA_Lahore_bm.tif'\n",
    "    legend = 'CZsum_poly'\n",
    "    \"\"\"\n",
    "    \n",
    "    # <basemap_name>_<feature_name>.tif\n",
    "    write_filename = filename.split('.')[0]+'_'+legend+'.tif'\n",
    "    write_filePath = os.path.join(working_dir, 'Inference', write_filename)\n",
    "    \n",
    "    if os.path.exists(write_filePath):\n",
    "        return\n",
    "    \n",
    "    legend_coor, shift_coord, map_im_cut_dims, map_patchs_dims = build_patch(filename, legend, patch_dims = (256,256))\n",
    "    \n",
    "    test_dataset = test_dataGenerator(filename = filename, legend = legend, patch_dims = (256,256))\n",
    "    \n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    predicted = unet.predict(test_dataset)\n",
    "\n",
    "    patched_predicted = np.reshape(predicted, (map_patchs_dims[0], map_patchs_dims[1], 1, 256, 256, 1))\n",
    "    unpatch_predicted = unpatchify(patched_predicted, (map_im_cut_dims[0], map_im_cut_dims[1], 1))\n",
    "    pad_unpatch_predicted = np.pad(unpatch_predicted, [(shift_coord[0], shift_coord[1]), (shift_coord[2], shift_coord[3]), (0,0)], mode='constant')\n",
    "#     pad_unpatch_predicted_threshold = np.where(pad_unpatch_predicted>0.98, 1, 0)\n",
    "    \n",
    "#     masked_img = map_mask(filename, pad_unpatch_predicted_threshold)\n",
    "\n",
    "#     # expand one more dimension and repeat the pixel value in the third axis\n",
    "#     final_raster = np.repeat(masked_img[:, :, np.newaxis], 3, axis=2).astype(np.uint8)\n",
    "    \n",
    "    pad_unpatch_predicted = (pad_unpatch_predicted*255).astype(int)\n",
    "\n",
    "    masked_img = map_mask(filename, pad_unpatch_predicted)\n",
    "    masked_img = masked_img.astype(np.uint8)\n",
    "\n",
    "    map_im = cv2.imread(os.path.join(working_dir, filename))\n",
    "    edges = cv2.Canny(map_im,10,300,L2gradient = True)\n",
    "    masked_masked_img = cv2.bitwise_and(masked_img, edges)\n",
    "    final_raster = np.repeat(masked_masked_img[:, :, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    cv2.imwrite(write_filePath, final_raster)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f2fbc",
   "metadata": {},
   "source": [
    "### Inference all the map in the Validation subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e256feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/home/shared/DARPA/eval_data_perfomer_shirui'\n",
    "tifPaths = glob(working_dir+'/*.tif')\n",
    "\n",
    "if not os.path.exists(os.path.join(working_dir, 'Inference')):\n",
    "    os.mkdir(os.path.join(working_dir, 'Inference'))\n",
    "    \n",
    "for tifPath in tifPaths:    \n",
    "    tifFile = tifPath.split('/')[-1]\n",
    "    jsonFile = tifFile.split('.')[0]+'.json'\n",
    "\n",
    "    with open(os.path.join(working_dir, jsonFile), 'r') as f:\n",
    "        jsonData = json.load(f)\n",
    "\n",
    "    for label_dir in jsonData['shapes']:\n",
    "        legend = label_dir['label']\n",
    "        if legend.endswith('_line'):\n",
    "            try:\n",
    "                getInferenceForEachLegend(tifFile, legend)\n",
    "            except:\n",
    "                print('this map with this legend has problem:  ', tifPaths, legend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-shirui_env]",
   "language": "python",
   "name": "conda-env-.conda-shirui_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
